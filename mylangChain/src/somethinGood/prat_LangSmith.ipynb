{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f07fa81a",
   "metadata": {},
   "source": [
    "##### 1) ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32e11ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4677d391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_y\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# .env íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0c7ac66",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "str expected, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# LangSmith API Key ì„¤ì •\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# getenvì˜ ë‘ ë²ˆì§¸ ì¸ìë¡œ ê¸°ë³¸ê°’ì„ ì„¤ì •í•˜ì—¬, í™˜ê²½ ë³€ìˆ˜ê°€ ì—†ì„ ë•Œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\u001b[39;00m\n\u001b[32m     17\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mLANGSMITH_TRACING\u001b[39m\u001b[33m\"\u001b[39m] = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mLANGSMITH_TRACING\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# LangSmith í™œì„±í™” (ê¸°ë³¸ê°’ \"true\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLANGSMITH_API_KEY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mLANGSMITH_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)      \u001b[38;5;66;03m# API Key ë¶ˆëŸ¬ì˜¤ê¸°\u001b[39;00m\n\u001b[32m     19\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mLANGSMITH_PROJECT\u001b[39m\u001b[33m\"\u001b[39m] = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mLANGSMITH_PROJECT\u001b[39m\u001b[33m\"\u001b[39m)      \u001b[38;5;66;03m# í”„ë¡œì íŠ¸ ì´ë¦„ ì„¤ì •\u001b[39;00m\n\u001b[32m     20\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mLANGSMITH_ENDPOINT\u001b[39m\u001b[33m\"\u001b[39m] = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mLANGSMITH_ENDPOINT\u001b[39m\u001b[33m\"\u001b[39m)      \u001b[38;5;66;03m# EndPoint ì„¤ì •\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:722\u001b[39m, in \u001b[36m__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:782\u001b[39m, in \u001b[36mcheck_str\u001b[39m\u001b[34m(value)\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: str expected, not NoneType"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langsmith import traceable\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "# ì´ ì½”ë“œëŠ” ë‹¤ë¥¸ os.getenv í˜¸ì¶œë³´ë‹¤ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "load_dotenv()\n",
    "\n",
    "# LangSmith API Key ì„¤ì •\n",
    "# getenvì˜ ë‘ ë²ˆì§¸ ì¸ìë¡œ ê¸°ë³¸ê°’ì„ ì„¤ì •í•˜ì—¬, í™˜ê²½ ë³€ìˆ˜ê°€ ì—†ì„ ë•Œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "os.environ[\"LANGSMITH_TRACING\"] = os.getenv(\"LANGSMITH_TRACING\", \"true\")  # LangSmith í™œì„±í™” (ê¸°ë³¸ê°’ \"true\")\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")      # API Key ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = os.getenv(\"LANGSMITH_PROJECT\")      # í”„ë¡œì íŠ¸ ì´ë¦„ ì„¤ì •\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = os.getenv(\"LANGSMITH_ENDPOINT\")      # EndPoint ì„¤ì •\n",
    "\n",
    "# LLM ëª¨ë¸ ì„¤ì • (Groq ì‚¬ìš©)\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",       # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),              # Groq API í‚¤ë„ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œ\n",
    "    model=\"llama3-70b-8192\",                        # Groqì—ì„œ ì§€ì›í•˜ëŠ” ëª¨ë¸ëª…ìœ¼ë¡œ ìˆ˜ì •\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# LangSmithë¡œ ì‹¤í–‰ ì¶”ì \n",
    "@traceable(run_type=\"chain\", name=\"Simple_Chain\")\n",
    "def ask_question(question: str):\n",
    "    \"\"\"ì§€ì •ëœ ì§ˆë¬¸ì— ëŒ€í•´ AI ëª¨ë¸ì—ê²Œ ë‹µë³€ì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "\n",
    "    # ê°œë³„ ë©”ì‹œì§€ í…œí”Œë¦¿ ì •ì˜\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\n",
    "        \"ë‹¹ì‹ ì€ ìœ ìš©í•œ AI ë¹„ì„œì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.\"\n",
    "    )\n",
    "    user_message = HumanMessagePromptTemplate.from_template(\n",
    "        \"{question}\"\n",
    "    )\n",
    "\n",
    "    # ì±„íŒ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        system_message,\n",
    "        user_message,\n",
    "    ])\n",
    "    \n",
    "    # í”„ë¡¬í”„íŠ¸ì™€ LLMì„ ì—°ê²°í•˜ëŠ” ì²´ì¸ ìƒì„±\n",
    "    chain = chat_prompt | llm\n",
    "\n",
    "    # ì²´ì¸ ì‹¤í–‰ ë° ê²°ê³¼ ë°˜í™˜\n",
    "    response = chain.invoke({\"question\": question})\n",
    "\n",
    "    return response.content\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "question = \"LangGraphì™€ LangChainì˜ ê°€ì¥ í° ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "answer = ask_question(question)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nğŸ”¹ [AI ë‹µë³€]:\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-JHcERFOP-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
