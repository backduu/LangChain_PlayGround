{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0acc778",
   "metadata": {},
   "source": [
    "# 📝 LangChain PromptTemplate 계열 정리\n",
    "* [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html#langchain_core.prompts.prompt.PromptTemplate)\n",
    "* [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "* [ChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html#langchain_core.prompts.chat.ChatMessagePromptTemplate)\n",
    "* [FewShotPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html#langchain_core.prompts.few_shot.FewShotPromptTemplate)\n",
    "* PartialPrompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf6aab8",
   "metadata": {},
   "source": [
    "## 1. PromptTemplate\n",
    "- 정의: 가장 기본적인 프롬프트 템플릿 클래스\n",
    "- 역할: 문자열 기반 프롬프트를 정의하고, {변수} 자리에 동적으로 값을 채워 넣음\n",
    "- 특징:\n",
    "    - 단일 문장/문단 프롬프트에 적합\n",
    "    - 변수 치환으로 재사용성 ↑\n",
    "    - LLM에 전달할 입력을 일관된 형식으로 유지 가능\n",
    "    - 사용 예시 상황: \"너는 친절한 카페 직원이야. {menu}에 대해 설명해줘.\"\n",
    "\n",
    "## 2. ChatPromptTemplate\n",
    "- 정의: 대화형 모델(Chat Model) 전용 프롬프트 템플릿\n",
    "- 역할: 여러 메시지(system, human, ai 등)를 순서대로 정의하고, 이를 하나의 대화 컨텍스트로 구성\n",
    "- 특징:\n",
    "    - 역할(role) 기반 메시지 관리 (system, human, ai, tool)\n",
    "    - MessagesPlaceholder 를 통해 동적 대화 삽입 가능\n",
    "    - ChatGPT 같은 대화형 모델에 최적화\n",
    "    - 사용 예시 상황: 시스템 메시지로 역할 정의 + 사용자 입력 + 이전 대화 맥락을 함께 전달\n",
    "\n",
    "## 3. ChatMessagePromptTemplate\n",
    "- 정의: 특정 역할(role) 을 가진 메시지 하나를 템플릿화한 클래스\n",
    "- 역할: system, human, ai 같은 개별 메시지를 템플릿으로 정의\n",
    "- 특징:\n",
    "    - ChatPromptTemplate 내부에서 메시지 단위로 활용\n",
    "    - 메시지마다 변수를 치환할 수 있음\n",
    "    - 사용 예시 상황: \"human: {question}\", \"system: 너는 수학 선생님이야.\"\n",
    "\n",
    "## 4. FewShotPromptTemplate\n",
    "- 정의: Few-shot 학습을 위한 프롬프트 템플릿\n",
    "- 역할: 여러 개의 예시(example)를 자동으로 삽입해 LLM이 패턴을 학습하도록 유도\n",
    "- 특징:\n",
    "    - 예시 리스트를 템플릿에 포함시켜 모델이 참고하도록 함\n",
    "    - 예시 포맷을 자동으로 반복 적용 가능\n",
    "    - Zero-shot → Few-shot으로 성능 향상 가능\n",
    "    - 사용 예시 상황: 질의응답 예시를 여러 개 넣고, 마지막에 새로운 질문을 던져 답변 유도\n",
    "\n",
    "## 5. PartialPrompt\n",
    "- 정의: 프롬프트 템플릿의 일부 변수를 미리 채워둔 상태로 만드는 기능\n",
    "- 역할: 자주 반복되는 변수 값을 고정해두고, 나머지만 실행 시점에 채움\n",
    "- 특징:\n",
    "    - 프롬프트 재사용성 극대화\n",
    "    - 공통 맥락(예: 역할, 도메인)을 미리 세팅 가능\n",
    "    - 사용 예시 상황: \"너는 {role} 전문가야.\" 에서 role=\"카페 직원\" 을 미리 채워두고, 질문만 매번 바꿔서 사용\n",
    "\n",
    "### 🚀 정리\n",
    "- PromptTemplate → 문자열 기반 기본 템플릿\n",
    "- ChatPromptTemplate → 대화형 모델용, 여러 메시지 관리\n",
    "- ChatMessagePromptTemplate → 개별 메시지 단위 템플릿\n",
    "- FewShotPromptTemplate → 예시(Few-shot) 포함 프롬프트\n",
    "- PartialPrompt → 일부 변수를 미리 채워둔 템플릿\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d621777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_y\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7dfe97",
   "metadata": {},
   "source": [
    "# PromptTemplate\n",
    "\n",
    "##### 1) PromptTemplate 의 from_template() 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8324e995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatGPT는 인터넷의 방대한 텍스트에서 다음 단어를 맞히는 훈련을 통해 언어 패턴을 학습한다.  \\n'\n",
      " '이 과정에서 트랜스포머라는 구조가 문장의 맥락을 기억하며 확률 기반으로 가장 적절한 단어를 선택한다.  \\n'\n",
      " '사람의 피드백을 추가로 반영해 원하지 않는 답변은 줄이고 유용한 답변은 늘리는 방식으로 성능을 끌어올린다.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해줘.\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    #model=\"openai/gpt-oss-120b\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3})\n",
    "pprint(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaae80e",
   "metadata": {},
   "source": [
    "##### 2) PromptTemplate 결합하기\n",
    "* 동일한 Prompt 패턴을 사용하지만 여러 개의 질문을 작성해서 LLM을 실행할 수도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "869d9273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('**학습 원리 (한국어 3문장)**  \\n'\n",
      " 'DeepSeek은 방대한 텍스트 데이터를 바탕으로 다음 토큰을 예측하는 사전 학습(pre-training) 후, 지시 '\n",
      " '따르기(instruction tuning)와 강화학습(RLHF)으로 정렬을 개선한다.  \\n'\n",
      " '전문 영역(코드·수학)에 특화된 추가 학습을 통해 일반 대화뿐 아니라 복잡한 추론 능력도 강화했다.  \\n'\n",
      " '모델 가중치를 공개함으로써 연구자가 직접 미세 조정·확장할 수 있도록 했다.\\n'\n",
      " '\\n'\n",
      " '**장점 요약**  \\n'\n",
      " '오픈소스·고성능·전문 분야 최적화, 한·영·중 다국어 능력, 상대적으로 저렴한 추론 비용, 연구자가 자유롭게 수정·재배포 가능.\\n'\n",
      " '\\n'\n",
      " '**Similar models (English)**  \\n'\n",
      " 'Models comparable to DeepSeek include Meta’s Llama-2/3, Mistral-7B, '\n",
      " 'Alibaba’s Qwen series, and TII’s Falcon, all of which are open-weight LLMs '\n",
      " 'that balance strong reasoning with commercial-friendly licenses.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해줘.\"\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "prompt_template.format(model_name=\"Deepseek\", count=3)\n",
    "\n",
    "combined_prompt = (\n",
    "    prompt_template\n",
    "        + PromptTemplate.from_template(\"\\n\\n그리고 {model_name} 모델의 장점을 요약해줘.\"\n",
    "        + \"{model_name} 모델과 비슷한 AI 모델은 어떤 것이 있는지에 대해서는 {language2}로 설명해줘\")\n",
    ")\n",
    "\n",
    "combined_prompt.format(model_name=\"Deepseek\", count=3, language2=\"영어\")\n",
    "# print(combined_prompt)\n",
    "\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\": \"Deepseek\", \"count\": 3, \"language2\": \"영어\"})\n",
    "\n",
    "pprint(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104a2010",
   "metadata": {},
   "source": [
    "#### PromptTemplate 의 파라미터를 배열 형태로 하여 여러개 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01758261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.', 'Gemini 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.', 'claude 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.']\n",
      "\n",
      "\n",
      "\n",
      "<class 'str'> GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.\n",
      "('GPT-4는 수많은 텍스트 데이터를 바탕으로 다음에 올 토큰을 예측하는 방식으로 학습됩니다.  \\n'\n",
      " '인간의 피드백을 통해 보상 모델을 만들어 강화학습으로 정답倾向을 조정합니다.  \\n'\n",
      " '결과적으로 통계적 패턴을 학습해 실제 이해는 없지만 자연스러운 대화를 생성합니다.')\n",
      "<class 'str'> Gemini 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Gemini는 텍스트·이미지·오디오 등 다양한 데이터를 동시에 처리하는 멀티모달 구조를 기반으로, 인코더-디코더 트랜스포머를 확장해 '\n",
      " '학습합니다.  \\n'\n",
      " '대규모 텍스트와 이미지 쌍을 먼저 학습한 뒤, 멀티모달 시퀀스를 하나의 시리즈로 이어 붙여 다음 토큰을 예측하는 자기 지도 방식으로 '\n",
      " '학습합니다.  \\n'\n",
      " '학습이 진행되면서 멀티모달 혼합 전문가(MoE) 레이어가 활성화되어 필요한 전문가 네트워크만 선택적으로 사용해 효율을 높입니다.  \\n'\n",
      " '지도 미세조정과 강화학습을 반복해 인간의 선호도에 맞춘 답변을 생성하도록 최적화됩니다.')\n",
      "<class 'str'> claude 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Claude는 방대한 텍스트 데이터를 학습해 언어 패턴을 익힌 뒤, 주어진 맥락에서 다음에 올 단어를 예측하는 방식으로 학습됩니다.  \\n'\n",
      " '인간이 작성한 프롬프트와 응답 쌍을 비교하며 보상 모델의 피드백으로 정답에 가까운 답변을 생성하도록 미세조정됩니다.  \\n'\n",
      " '강화학습과 인간 피드백(RLHF)을 반복해 유용성, 정직성, 무해성을 동시에 높이는 방향으로 최적화됩니다.  \\n'\n",
      " '결국 통계적 확률 계산만으로도 사고처럼 보이는 연결을 만들어 낼 수 있게 됩니다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 3},\n",
    "    {\"model_name\": \"Gemini\", \"count\": 4},\n",
    "    {\"model_name\": \"claude\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "print(\"\\n\\n\")\n",
    "for prompt in formatted_prompts:\n",
    "    print(type(prompt), prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f36599",
   "metadata": {},
   "source": [
    "# ChatPromptTemplate\n",
    "\n",
    "* Tuple 형태의 system, user, assistant 메시지 지원\n",
    "* 여러 개의 메시지를 조합하여 LLM에게 전달 가능\n",
    "* 간결성과 가독성이 높고 단순한 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9556f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upstage에서 배포하는 거대언어모델(이하 ‘업스테이지 모델’)은 GPT-3·GPT-4 같은 일반적인 트랜스포머 디코더 계열 모델과 큰 틀에서 동일한 ‘사전학습(Pre-training) → 미세조정(Fine-tuning) → 정렬(Alignment)’ 3단계를 거친다. 핵심은 각 단계에서 한국어·한국 업무 도메인 특화된 데이터와 기술을 집어넣어 “한국어에 특화된 업무 성능”을 끌어올리는 것이다. 아래에서 핵심 원리만 한글로 풀어 설명한다.\n",
      "\n",
      "-------------------------------------------------\n",
      "1. 사전학습(Pre-training) 단계\n",
      "-------------------------------------------------\n",
      "1) 학습 목표  \n",
      "주어진 토큰 시퀀스의 다음 토큰을 맞추는 “자기회귀(Self-Regression)” 문제를 푼다.  \n",
      "예) “오늘 날씨가 ___” → “좋다”를 예측\n",
      "\n",
      "2) 신경망 구조  \n",
      "- 트랜스포머 디코더 블록 × N층  \n",
      "- Multi-Head Self-Attention + FFN + 잔차연결 + LayerNorm  \n",
      "- 어텐션 마스크: 미래 토큰을 못 보게(캐주얼 마스크)  \n",
      "- 위치 임베딩: 회전 위치 임베딩(RoPE)이나 ALiBi 등 최신 위치 인코딩 사용  \n",
      "- 활성화 함수: SwiGLU, GELU 등 변형\n",
      "\n",
      "3) 데이터  \n",
      "- 1~2조 토큰 규모.  \n",
      "- 한국어 비중 30~50% 이상(공개 모델 대비 5~10배 ↑)  \n",
      "- 한국어 웹·뉴스·판례·의학·금융·공공 데이터 적극 포함  \n",
      "- 전처리: 중복 제거·문장 분리·세그먼트 필터링·PPL 기반 품질 점수 0.3 이하만 채택  \n",
      "- 토큰나이저: BPE/BBPE 기반, 한국어 형태소 정보 반영(한글 음절·자소 단위 분해 X)\n",
      "\n",
      "4) 최적화 트릭  \n",
      "- bfloat16/FP16 혼합 정밀도, ZeRO-3, 텐서·파이프라인 병렬  \n",
      "- FlashAttention, fused kernels, sequence parallelism  \n",
      "- 학습률 스케줄: cosine + linear warmup + min-lr 1/10 감쇠  \n",
      "- 토큰 단위 손실에 길이 가중치(length penalty) 적용 → 긴 문서 학습 안정화  \n",
      "- 1~2 epoch만 돌려 over-fit 방지\n",
      "\n",
      "5) 결과  \n",
      "웹 텍스트 기반 “공통 한국어 지식 + 일반 상식”을 학습한 베이스 모델이 완성됨.\n",
      "\n",
      "-------------------------------------------------\n",
      "2. 지도 미세조정(Supervised Fine-Tuning, SFT)\n",
      "-------------------------------------------------\n",
      "1) 목표  \n",
      "지시(Instruction)에 맞춰 ‘요약·번역·추론·분류·코드 생성’ 등 다양한 테스크를 수행하도록 방향을 잡아준다.\n",
      "\n",
      "2) 데이터  \n",
      "- 한국어 instruction 데이터 100만~300만 개  \n",
      "- 업무 도메인(법률·세무·의료·공공·금융) instruction 30% 이상  \n",
      "- Human-annotated + LLM-Augmented(거대모델로 증강) 병행  \n",
      "- 프롬프트 템플릿 다양화(1 instruction → 3~5 paraphrase)\n",
      "\n",
      "3) 학습  \n",
      "- 동일한 자기회귀 손실, 단 ‘assistant’ 부분만 손실 계산  \n",
      "- Learning-rate = 사전학습 대비 1/10~1/30 수준(1e-5~5e-6)  \n",
      "- Epoch = 2~3, early stopping(PPL, Rouge 기준)\n",
      "\n",
      "4) 결과  \n",
      "지시 따르기(Instruction Following) 성능이 크게 향상됨. 한국어 지시 성능은 공개 LLaMA-2-ko 대비 평균 15~20%p ↑\n",
      "\n",
      "-------------------------------------------------\n",
      "3. 보상 모델 및 인간 정렬(RLHF / RLAIF / DPO)\n",
      "-------------------------------------------------\n",
      "1) 보상 모델(Reward Model) 학습  \n",
      "- Upstage 내부 평가원 + 외부 크라우드소싱 → 10만 쌍 이상의 ‘선호도 데이터’ 구축  \n",
      "- 입력: 프롬프트 + 응답 A vs B  \n",
      "- 출력: A가 B보다 좋은지 확률(Regression)  \n",
      "- 트랜스포머主干 + 풀링 + 선형 회귀 헤드  \n",
      "- 손실: Pairwise ranking loss(Bradley-Terry)\n",
      "\n",
      "2) 강화학습 정렬  \n",
      "- PPO(Proximal Policy Optimization) 기반 RLHF  \n",
      "- KL-penalty(베이스 모델 대비 divergence 제한) → too short/too repetitive 방지  \n",
      "- 길이 규제, 안전 규제(도덕·법률·혐오 표현 필터) 추가 보상 항  \n",
      "- 50~100 step만 수행해도 대화 품질·안전성이 올라감\n",
      "\n",
      "3) 최신 방식(DPO, RLAIF)  \n",
      "- PPO 대비 학습이 단순하고 불안정성↓  \n",
      "- Direct Preference Optimization: 보상 모델 없이 preference 쌍만으로 policy 최적화  \n",
      "- RLAIF: Google 방식, LLM이 ‘추천 이유’를 달아서 선호도 레이블 생성 → 사람 1/5 수준만 수작업\n",
      "\n",
      "4) 결과  \n",
      "- 헛소리(Hallucination) ↓30%  \n",
      "- 유해 출력(폭력·차별·성적) 필터링 통과율 96%↑  \n",
      "- 대화 연속성, 친절도, 포멧팅 정확도 개선\n",
      "\n",
      "-------------------------------------------------\n",
      "4. 한국어·도메인 특화 추가 기술\n",
      "-------------------------------------------------\n",
      "1) 어휘&문법 특화  \n",
      "- 한국어 조사·높임법·존댓말 태스크를 instruction tuning에 15% 반영  \n",
      "- ‘-습니다/-해요/-한다’ 체계를 모두 학습하도록 교차 편집\n",
      "\n",
      "2) 전문 용어 사전 주입  \n",
      "- 법률용어, 의학 용어, 금융 용어를(약 50만 개) ‘스팟 어닝(Spot Embedding)’ 기법으로 사전에 주입 → 추후 오타·신조어에도 강인\n",
      "\n",
      "3) 한영 혼용 처리  \n",
      "- Kor→Eng, Eng→Kor 번역 instruction 10만 쌍 추가 → 혼용 문장 처리력 향상\n",
      "\n",
      "4) 문서 길이 확장  \n",
      "- 위치 인코딩을 RoPE + Linear interpolation → 4K → 32K 확장  \n",
      "- 긴 판결문/논문 요약 정확도 ↑\n",
      "\n",
      "-------------------------------------------------\n",
      "5. 평가 & 지속적 학습\n",
      "-------------------------------------------------\n",
      "1) 내부 벤치  \n",
      "- Upstage 한국어 종합 벤치(UKB) 12개 테스크  \n",
      "- 법률 QA, 세무 QA, 의학 QA, Summarization, Hallucination check 등  \n",
      "- 매 주 릴리즈마다 점수 기록 → 회귀 방지\n",
      "\n",
      "2) 외부 벤치  \n",
      "- Ko-ARC, Ko-HellaSwag, KLUE, KMMLU, KoBEST 등  \n",
      "- Ko-HumanEval(코드), Ko-MMLU(상식) 동시 측정\n",
      "\n",
      "3) 지속적 학습(Continual Learning)  \n",
      "- 새로운 논문·판례·뉴스를 계속 모아 ‘점진적 사전학습’( continual pre-training)  \n",
      "- Elastic Weight Consolidation(EWC)로 망각 현상(catastrophic forgetting) 최소화\n",
      "\n",
      "-------------------------------------------------\n",
      "6. 요약\n",
      "-------------------------------------------------\n",
      "1) 트랜스포머 자기회귀 언어 모델링이 핵심  \n",
      "2) 한국어·업무 데이터를 대량으로 넣어 ‘한국어 특화 사전학습’  \n",
      "3) Instruction 데이터로 지시 수행 능력 강화(SFT)  \n",
      "4) 사람 선호도 학습(RLHF/DPO)로 안전성·정보 정확도·대화 품질 정렬  \n",
      "5) 법률·세무·의료·금융 등 전문 도메인 데이터 + 평가 지표로 품질 검증 및 지속 개선\n",
      "\n",
      "이런 식으로 “한국어에 최적화된 업무용 LLM”을 만들어 낸 것이 Upstage 모델의 학습 원리이다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# 튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"{topic}에 대해 넌 아주 자세히 알고 있기에 답변도 명확하고 자세하게 해줄 수 있어.\"),\n",
    "        (\"human\", \"{model_name} 모델의 학습 원리를 한글로 설명해줘\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", model_name=\"Upstage\")\n",
    "\n",
    "# 생성한 메시지 바로 주입해서 호출출\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "879b0c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatGPT는 GPT(Generative Pre-trained Transformer) 아키텍처를 기반으로 한 대규모 언어 '\n",
      " '모델(LLM)이다.  \\n'\n",
      " '‘학습’은 크게 1) Pre-training(사전 학습), 2) SFT(Supervised Fine-Tuning), 3) '\n",
      " 'RLHF(Reinforcement Learning from Human Feedback) 세 단계로 나뉜다.  \\n'\n",
      " '각 단계마다 쓰이는 데이터 종류·양, 목적 함수, 최적화 기법이 다르므로 아래에 단계별로 ‘무엇을’, ‘어떻게’, ‘왜’를 한글로 자세히 '\n",
      " '풀어 설명한다.\\n'\n",
      " '\\n'\n",
      " '--------------------------------------------------\\n'\n",
      " '1. Pre-training (사전 학습)  \\n'\n",
      " '목표: 인터넷에 존재하는 방대한 텍스트를 통해 “일반적인 언어 지식”을 압축한다.  \\n'\n",
      " '데이터: 웹페이지, 책, 위키, 논문, 코드 등 수십 TB 급 텍스트.  \\n'\n",
      " '형식: 단순히 다음 토큰(token) 예측(next-token prediction)만으로 학습.  \\n'\n",
      " '– 토큰 ≈ 단어 or 부분 단어.  \\n'\n",
      " '– 입력 시퀀스 x=(x₁…xₜ)가 주어졌을 때 p(xₜ₊₁|x₁…xₜ)를 최대화.  \\n'\n",
      " '\\n'\n",
      " '모델 구조  \\n'\n",
      " '– Transformer 디코더 블록 96개, 임베딩 차원 12 288, 헤드 96개 등 초거대 파라미터(예: GPT-3 '\n",
      " '175B).  \\n'\n",
      " '– Self-attention이 전체 문맥을 한꺼번에 볼 수 있어 장거리 의존성 학습에 탁월.  \\n'\n",
      " '\\n'\n",
      " '최적화  \\n'\n",
      " '– AdamW, 배치 크기 수천~수만, 학습률 스케줄링(cosine decay + linear warmup).  \\n'\n",
      " '– 수십 일~수백 일 동안 수천 개 GPU/TPU로 분산 학습.  \\n'\n",
      " '– 정규화: Dropout, weight decay, gradient clipping.  \\n'\n",
      " '\\n'\n",
      " '결과  \\n'\n",
      " '– ‘확률적 다음 단어 생성기’ 완성.  \\n'\n",
      " '– 질문·대화·요약·번역 등 어떤 프롬프트든 자연스러운 ‘이어쓰기’는 가능하지만, “정답률”은 보장되지 않음(허구·편향·유해 답변 '\n",
      " '가능).  \\n'\n",
      " '--------------------------------------------------\\n'\n",
      " '2. SFT (지도 미세 조정, Supervised Fine-Tuning)  \\n'\n",
      " '목표: Pre-trained 모델이 “사람이 선호하는 대화 형식”을 배우게 한다.  \\n'\n",
      " '데이터: (프롬프트, 이상적인 응답) 쌍 1~10만 개.  \\n'\n",
      " '– 프롬프트는 다양한 지시형(instruction) 템플릿.  \\n'\n",
      " '– 응답은 인간 라벨러가 직접 작성하거나, 더 큰 모델·검증 파이프라인을 거쳐 품질 확보.  \\n'\n",
      " '\\n'\n",
      " '학습 방식  \\n'\n",
      " '– 똑같은 next-token prediction loss를 사용하되, 라벨이 있는 ‘정답’ 시퀀스만큼만 손실을 계산.  \\n'\n",
      " '– 보통 1~3 epoch, 학습률은 pre-training 대비 10~100분의 1 수준으로 작게.  \\n'\n",
      " '– 어휘·사실 지식은 대부분凍結하지 않고, 파라미터 전체를 미세 조정(“full fine-tune”)하거나 LoRA/AdaLoRA 같은 '\n",
      " '저秩適配기법을 쓰기도 함.  \\n'\n",
      " '\\n'\n",
      " '효과  \\n'\n",
      " '– “도움이 되고·무해하며·간결한” 형식을 암기.  \\n'\n",
      " '– but 아직 “정답이 맞는지”는 검증 불가 → RLHF 단계로 이어짐.  \\n'\n",
      " '--------------------------------------------------\\n'\n",
      " '3. RLHF (인간 피드백 기반 강화학습)  \\n'\n",
      " '목표: “사람이 더 선호하는 응답”을 스칼라 보상 값으로 바꿔 정책(policy)을 개선.  \\n'\n",
      " '과정  \\n'\n",
      " '① 보상 모델(RM, Reward Model) 학습  \\n'\n",
      " '– 같은 프롬프트에 대한 여러 개의 후보 응답을 라벨러가 비교(예: A>B>C).  \\n'\n",
      " '– Preference pair로 변환해, RM이 “더 좋은 쪽”의 로짓이 높아지도록 Bradley-Terry 손실로 학습.  \\n'\n",
      " '– RM 역시 Transformer 기반, 출력은 단일 스칼라.  \\n'\n",
      " '\\n'\n",
      " '② 강화학습으로 정책 업데이트  \\n'\n",
      " '– 기본 정책 π₀: 위 SFT 모델.  \\n'\n",
      " '– 보상: RM 출력 + KL penalty(π₀와의 분산 차이 제한)  \\n'\n",
      " '– 알고리즘: PPO (Proximal Policy Optimization)  \\n'\n",
      " '– 에피소드: (상태=프롬프트, 행동=토큰 생성, 보상=RM, 종료=EOS)  \\n'\n",
      " '– 수천~수만 회 반복하며 π가 점점 “사람이 높게 평가할 확률”을 최대화.  \\n'\n",
      " '\\n'\n",
      " '③ 반복  \\n'\n",
      " '– 새로 개선된 정책으로 또 다른 후보 응답을 샘플링 → 라벨러가 다시 선호도 표시 → RM 재학습 → RL 재학습.  \\n'\n",
      " '– 2~3 회 반복하면 RM이 과적합되지 않도록 주의.  \\n'\n",
      " '\\n'\n",
      " '효과  \\n'\n",
      " '– 허위·유해·무성의 답변 비율이 현저히 감소.  \\n'\n",
      " '– 길이·형식·친절도 등 인간 미적 기준 반영.  \\n'\n",
      " '--------------------------------------------------\\n'\n",
      " '4. (선택) 추가 안전/유용성 필터  \\n'\n",
      " '– Moderation API: 유해·편집권·성적·폭력 키워드 필터링.  \\n'\n",
      " '– 거부( Refusal) 튜닝: “나쁜 행동을 가르쳐 달라”는 요청엔 거절 메시지 생성하도록 SFT+RLHF 추가 데이터 주입.  \\n'\n",
      " '--------------------------------------------------\\n'\n",
      " '정리  \\n'\n",
      " '1. Pre-training → “언어를 안다”  \\n'\n",
      " '2. SFT → “지시에 맞는 형식을 안다”  \\n'\n",
      " '3. RLHF → “사람이 선호하는 품질을 안다”  \\n'\n",
      " '\\n'\n",
      " '이 세 단계를 거쳐 탄생한 모델이 우리가 쓰는 ChatGPT다.')\n"
     ]
    }
   ],
   "source": [
    "# 체인을 만들어 호출하기\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"topic\":\"AI\", \"model_name\":\"ChatGPT\"})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7babfe10",
   "metadata": {},
   "source": [
    "* SystemMessagePromptTemplate와 HumanMessagePromptTemplate 클래스 사용\n",
    "* 객체 지향적 접근 - Message 객체를 독립적으로 생성 가능\n",
    "* 여러 조건에 따라 다른 시스템 메시지 선택\n",
    "\n",
    "```python\n",
    "if user_is_beginner:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"초보자를 위한 설명: {topic}\")\n",
    "else:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"전문가를 위한 상세 분석: {topic}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4212853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "(내용은 정확하지만, 실제 AI는 이렇게 말하지 않는다.)\n",
      "\n",
      "---\n",
      "\n",
      "**딥러닝(Deep Learning)이란?**\n",
      "\n",
      "1. **정의**  \n",
      "   딥러닝은 인공신경망(Artificial Neural Network)을 여러 겹(‘깊게’) 쌓아서 데이터 속에서 **고차원적인 패턴**을 스스로 학습하는 기술이다.  \n",
      "   - ‘깊다(deep)’ ≠ 지능이 높다.  \n",
      "   - ‘깊다’ = 층(layer)이 많다(보통 5층 이상, 수십·수백층도 가능).\n",
      "\n",
      "2. **핵심 원리**  \n",
      "   1. **가중치(weight)와 편향(bias)**라는 매개변수 집합을 랜덤 초기화.  \n",
      "   2. **순전파(forward pass)**: 입력(x) → 층마다 행렬곱·활성화함수 → 예측(ŷ)  \n",
      "   3. **손실함수(loss)**: ŷ와 정답 y의 차이를 수치화(예: 교차엔트로피, MSE)  \n",
      "   4. **역전파(back-propagation)**: 손실 기울기(∂Loss/∂W)를 체인룰로 자동 미분.  \n",
      "   5. **옵티마이저(gradient descent 계열)**: 기울기 방향으로 가중치를 조정.  \n",
      "   6. 위 2~5를 수백만 번 반복하며 손실이 최소화 → 모델 수렴.\n",
      "\n",
      "3. **왜 ‘깊게’ 쌓는가?**  \n",
      "   - 얕은 네트워크는 XOR 같은 간단한 비선형 문제도 해결 못 함(뉴럴 네트워크 근본정리, 1989).  \n",
      "   - 층을 깊게 쌓으면 **특성 재사용**이 가능: 저층은 선·모서리 → 중층은 모양 → 고층은 고양이 얼굴처럼 복잡한 개념.  \n",
      "   - 파라미터 효율성: 깊은 네트워크가 넓은 네트워크보다 동일 표현력에 파라미터 수가 훨씬 적음(예: 1억 개 파라미터로 1000만 장 분류 가능).\n",
      "\n",
      "4. **주요 구성 요소**  \n",
      "   - **활성화 함수**: ReLU·GELU·Swish 등(비선형성 제공, 기울기 소실/폭발 완화)  \n",
      "   - **정규화**: BatchNorm, LayerNorm(내부 공변량 이동 문제 해결)  \n",
      "   - **드롭아웃**: overfitting 억제  \n",
      "   - **잔차 연결(ResNet)**: skip connection으로 1000층 이상도 학습 가능  \n",
      "   - **고급 구조**: CNN(공간 인variance), RNN/LSTM/Transformer(시간·문서 모델링), Diffusion·GAN(생성)\n",
      "\n",
      "5. **학습 조건**  \n",
      "   - **Big-data**: ImageNet 1400만 장, Common Crawl 수 TB급 문서 등.  \n",
      "   - **Big-compute**: GPU/TPU 수천 개, 수백~수천 petaFLOPS·일.  \n",
      "   - **Big-model**: 언어 모델 기준 수억~수조 파라미터.  \n",
      "   - **Regularization + optimization tricks**: 초거대 모델도 일반화 성능 확보.\n",
      "\n",
      "6. **특징**  \n",
      "   - **End-to-end**: 특성 공학 안 해도 됨(원시 픽셀·음성·단어만 주면 됨).  \n",
      "   - **Representation learning**: 데이터만 주면 중요한 특징을 스스로 발견.  \n",
      "   - **Scalability**: 데이터·파라미터·컴퓨터 증가 시 성능이 지속 상슴(‘스케일링 법칙’).  \n",
      "   - **Black-box**: 해석이 어렵고, 적대적 예시에 취약.\n",
      "\n",
      "7. **주요 응용 분야**  \n",
      "   - 컴퓨터 비전: 분류(ResNet·EfficientNet), 객체 탐지(YOLO·DETR), 의료 영상 판독, 자율주행 인식  \n",
      "   - 자연어 처리: 기계번역, 챗봇(ChatGPT), 요약, 감정 분석  \n",
      "   - 음성·음악: 음성 인식(Whisper), 음성 합성, 노래 생성  \n",
      "   - 생성: 이미지(DALL·E·Stable Diffusion), 영상, 3D 모델  \n",
      "   - 과학·공학: 단백질 구조 예측(AlphaFold), 기상 예측, 신약 후보 탐색\n",
      "\n",
      "8. **딥러닝의 역사(핵심만)**  \n",
      "   - 1943 McCulloch-Pitts 뉴런  \n",
      "   - 1986 역전파 일반화(Rumelhart·Hinton)  \n",
      "   - 2006 깊은 네트워크 사전학습(Hinton 등) → ‘Deep Learning’ 탄생  \n",
      "   - 2012 ImageNet CNN(AlexNet) → GPU+대데이터 증명  \n",
      "   - 2014 GAN, 2017 Transformer → 생성·언어 분야 폭발  \n",
      "   - 2020 이후 100B~1T 파라미터 초거대 모델(GPT-3·PaLM), 멀티모달 확산\n",
      "\n",
      "9. **한계 및 과제**  \n",
      "   - **데이터·계산 비용**: 수백만 달러, 친환경 이슈  \n",
      "   - **설명성**: 의료·금융 등 규제 분야 도입 난이도  \n",
      "   - **강건성**: 적대적 예시, 배포 후 분포 변화(robustness·OOD)  \n",
      "   - **편향·윤리**: 훈련 데이터의 인종·성별 편향 증폭 가능  \n",
      "   - **지속적 학습**: 새로운 데이터만 주면 catastrophic forgetting 해결 중\n",
      "\n",
      "10. **딥러닝 ≠ 인공지능 전부**  \n",
      "    AI > Machine Learning > Deep Learning.  \n",
      "    딥러닝은 ML의 한 갈래이며, 기호기반·진화·강화학습·전문가 시스템 등과 함께 AI를 구성.\n",
      "\n",
      "---\n",
      "\n",
      "**요약 한 줄**  \n",
      "딥러닝은 ‘층이 깊은’ 인공신경망으로, 대규모 데이터와 연산을 통해 특성을 스스로 학습하여 이미지·언어·음성·생성 등 인간 수준 이상의 성능을 내는 현대 AI의 핵심 동력이다.\n"
     ]
    }
   ],
   "source": [
    "# ChatMessagePromptTemplate 활용\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"{topic}에 대해서 넌 잘 알고 있는 편이야. 명확하고 자세하게 설명해줘\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"이건 {topic}에 대한 예시 설명이다.\"\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message, user_message, ai_message]\n",
    ")\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"딥러닝이 뭐야?\")\n",
    "\n",
    "# LLM 호출\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5452bf",
   "metadata": {},
   "source": [
    "#### ChatMessagePromptTemplate는 여러 종류의 메시지(시스템, 인간, AI)를 조합하여 복잡한 프롬프트를 생성할 때 유용합니다.\n",
    "* SystemMessagePromptTemplate: 이 템플릿은 AI 모델에게 역할을 부여하거나 전반적인 규칙을 설정하는 시스템 메시지를 만듭니다. 위의 예시에서는 \"번역을 도와주는 유용한 도우미\"라는 역할을 지정합니다.\n",
    "\n",
    "* HumanMessagePromptTemplate: 이 템플릿은 사용자의 질문이나 요청을 담는 인간 메시지를 만듭니다. 아래의 예시에서는 번역할 텍스트를 입력받습니다.\n",
    "\n",
    "* ChatPromptTemplate.from_messages: 이 클래스 메서드는 시스템 메시지, 인간 메시지 등 여러 종류의 MessagePromptTemplate 객체들을 리스트로 받아 하나의 채팅 프롬프트 템플릿으로 통합합니다.\n",
    "\n",
    "* format_messages: 이 메서드는 정의된 템플릿에 실제 값을 채워 넣어 [SystemMessage, HumanMessage] 형태의 리스트를 반환합니다. 이 리스트는 채팅 모델(Chat Model) 에 바로 전달될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f15c577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant that translates English to Korean.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={})]\n",
      "나는 프로그래밍을 사랑해.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 1. SystemMessagePromptTemplate와 HumanMessagePromptTemplate 생성\n",
    "# SystemMessagePromptTemplate는 모델의 페르소나 또는 기본 지침을 설정합니다.\n",
    "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# HumanMessagePromptTemplate는 사용자로부터 받는 입력 프롬프트를 정의합니다.\n",
    "human_template = \"{text_to_translate}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 2. ChatPromptTemplate 생성\n",
    "# 위에서 만든 두 템플릿을 리스트로 묶어 ChatPromptTemplate을 만듭니다.\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# 3. 프롬프트 포맷팅\n",
    "# chat_prompt_template.format_messages()를 사용하여 최종 메시지 리스트를 생성합니다.\n",
    "# 이 함수는 딕셔너리 형태의 입력 변수를 받습니다.\n",
    "formatted_prompt = chat_prompt_template.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Korean\",\n",
    "    text_to_translate=\"I love programming.\"\n",
    ")\n",
    "\n",
    "# 4. 결과 출력\n",
    "print(formatted_prompt)\n",
    "\n",
    "# LLM 호출\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff195385",
   "metadata": {},
   "source": [
    "# FewShotPromptTemplate\n",
    "* FewShotPromptTemplate은 모델이 특정 형식을 따르게 하거나, 일관된 응답을 생성하도록 유도할 때 유용합니다.\n",
    "* 도메인 지식이 필요하거나, AI가 오답을 줄이고 더 신뢰할 만한 답변을 생성하도록 해야 할 때 효과적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e57f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001CBD7251A90> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001CBD7252510> root_client=<openai.OpenAI object at 0x000001CBD6AB7380> root_async_client=<openai.AsyncOpenAI object at 0x000001CBD7252270> model_name='moonshotai/kimi-k2-instruct-0905' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n",
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': '뉴턴의 운동 법칙을 요약해 주세요.', 'output': '### 뉴턴의 운동 법칙\\n1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\\n2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\\n3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.'}, {'input': '지구의 대기 구성 요소를 알려주세요.', 'output': '### 지구 대기의 구성\\n- **질소 (78%)**: 대기의 대부분을 차지합니다.\\n- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\\n- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\\n- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001CBD7251A90>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001CBD7252510>, root_client=<openai.OpenAI object at 0x000001CBD6AB7380>, root_async_client=<openai.AsyncOpenAI object at 0x000001CBD7252270>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "양자컴퓨터는 “동전을 던지기 전에 앞면·뒷면이 동시에 존재하듯” 0과 1이 한꺼번에 섞인 특별한 정보 조각, **‘큐비트’** 를 이용해 계산하는 컴퓨터예요.  \n",
      "\n",
      "1. 일반 컴퓨터는 전구처럼 **켜짐(1)** 또는 **꺼짐(0)** 둘 중 하나만 표현하지만,  \n",
      "2. 큐비트은 마치 “회전하는 동전”처럼 **켜짐과 꺼짐이 동시에 섞인 상태**를 가질 수 있어요.  \n",
      "3. 이런 섞인 상태가 많은 큐비트들이 **서로 손잡고 있으면(얽힘)** 한 번에 엄청 많은 경우의 수를 동시에 확인할 수 있어요.  \n",
      "\n",
      "따라서 복잡한 길 찾기, 암호 풀기, 새로운 약 찾기처럼 **가짓수가 엄청 많은 문제**를 훨씬 빨리 해결할 수 있게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate 사용하는 경우\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "chain = final_prompt | llm\n",
    "print(llm)\n",
    "print(chain)\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"양자컴퓨팅에 대하여 설명해 주세요.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea9dbc",
   "metadata": {},
   "source": [
    "# 📝 메시지 구조 정리\n",
    "1. system\n",
    "- 정의: 모델에게 주어지는 역할 지시(Role Instruction)\n",
    "- 역할: 모델이 어떤 톤, 스타일, 관점으로 답해야 하는지 규정\n",
    "- 예시:\n",
    "    - \"너는 친절한 카페 직원이야.\"\n",
    "    - \"너는 초등학생도 이해할 수 있게 설명하는 과학 선생님이야.\"\n",
    "\n",
    "2. human\n",
    "- 정의: 실제 사용자가 모델에게 던지는 입력(질문/요청)\n",
    "- 역할: 대화에서 사람의 발화를 표현\n",
    "- 예시:\n",
    "    - \"아메리카노 가격 알려줘.\"\n",
    "    - \"양자컴퓨팅을 쉽게 설명해줘.\"\n",
    "\n",
    "3. ai\n",
    "- 정의: 모델이 과거에 했던 응답(답변) 을 나타내는 메시지\n",
    "- 역할: 대화 맥락을 이어가기 위해 AI의 이전 발화를 포함시킬 때 사용\n",
    "- 예시:\n",
    "    - \"아메리카노는 4,500원입니다.\"\n",
    "    - \"양자컴퓨팅은 양자역학 원리를 이용한 새로운 계산 방식입니다.\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6788371f",
   "metadata": {},
   "source": [
    "# 📝 FewShotChatMessagePromptTemplate 정리\n",
    "## 1. 개념\n",
    "- LangChain의 Few-shot 프롬프트 템플릿 중 하나\n",
    "- 대화형(Chat) 모델에 맞게, 예시 대화(few-shot examples) 를 메시지 형태로 삽입할 수 있도록 설계된 클래스\n",
    "- 즉, 모델에게 “이런 식으로 질문과 답변을 주고받는다”는 패턴을 학습시켜주는 역할\n",
    "\n",
    "## 2. 구조\n",
    "- 예시(example): {input: \"...\", output: \"...\"} 형태의 딕셔너리 리스트\n",
    "- example_prompt: 각 예시를 어떻게 메시지로 표현할지 정의\n",
    "(예: (\"human\", \"{input}\"), (\"ai\", \"{output}\"))\n",
    "- FewShotChatMessagePromptTemplate: 위 예시들을 반복적으로 적용해 최종 프롬프트에 삽입\n",
    "\n",
    "## 3. 동작 방식\n",
    "- examples 리스트에 질문-답변 쌍을 준비\n",
    "- example_prompt 로 각 예시를 메시지 형식(human, ai)으로 변환\n",
    "- FewShotChatMessagePromptTemplate 가 이 예시들을 모아 프롬프트 중간에 삽입\n",
    "- 최종적으로 system → few-shot examples → human 입력 순서로 모델에 전달\n",
    "\n",
    "## 4. 특징\n",
    "- Few-shot 학습: 모델이 예시를 보고 패턴을 학습 → 새로운 입력에도 유사한 형식으로 답변\n",
    "- Chat 전용: 단순 텍스트가 아니라 system, human, ai 메시지 구조를 유지\n",
    "- 유연성:\n",
    "- 고정된 예시 리스트 사용 가능\n",
    "- 또는 ExampleSelector 와 결합해 입력과 유사한 예시만 동적으로 선택 가능\n",
    "\n",
    "## 5. 장점\n",
    "- 모델이 일관된 답변 형식을 유지하도록 유도\n",
    "- 복잡한 개념도 예시 기반 설명으로 쉽게 전달 가능\n",
    "- Zero-shot 대비 정확도와 안정성 향상\n",
    "\n",
    "## 6. 사용 예시 상황\n",
    "- 교육용 챗봇: 과학 개념을 초등학생 눈높이에 맞게 설명\n",
    "- FAQ 챗봇: 자주 묻는 질문-답변 패턴을 예시로 제공\n",
    "- 포맷 강제: 답변을 항상 특정 구조(예: Markdown, JSON)로 출력하도록 유도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70827306",
   "metadata": {},
   "source": [
    "# PartialPrompt \n",
    "* 프롬프트를 더 동적으로 활용할 수 있으며, AI 응답을 더 일관성 있게 조정 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c47a6453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 가을에 일어나는 대표적인 지구과학 현상은 태풍 발생이 맞나요?         가을에 주로 발생하는 지구과학 현상을 3개 알려주세요\n",
      " 모델 응답: 가을에 일어나는 **지구과학 현상** 중 **태풍 발생**은 **맞을 수도 있지만**, **대표적이라고 보기는 어렵습니다**.  \n",
      "태풍은 **여름~초가을(7~9월)** 에 집중되지만, **가을에만 특별히 제한되는 현상은 아닙니다**.\n",
      "\n",
      "---\n",
      "\n",
      "### ✅ 가을에 **주로 발생하거나 특히 두드러지는** 지구과학 현상 3가지:\n",
      "\n",
      "1. **단풍 시작 (식생 계절 변화)**  \n",
      "   - **원인**: 일조 시간 감소 + 기온 하강 → 클로로필 분해 → 안토시아닌 등 색소가 드러남  \n",
      "   - **지구과학적 관점**: **기후와 생태계의 계절적 상호작용**\n",
      "\n",
      "2. **이시계(移시계) 현상**  \n",
      "   - **정의**: 하루 중 **기온이 가장 높은 시각**이 **여름보다 늦어지는 현상**  \n",
      "   - **원인**: 지면이 축열된 열이 서서히 방출되며 기온이 최고치에 이르는 시점이 늦어짐  \n",
      "   - **가을에 특히 뚜렷하게 관찰됨**\n",
      "\n",
      "3. **극야·극주 현상의 변화 (고위도 지역)**  \n",
      "   - **정의**: 북극이나 남극 근방에서 **낮과 밤의 길이가 급격히 변하는 시기**  \n",
      "   - **가을에는** **극주(밤이 계속되는 현상)** 가 시작되는 시점  \n",
      "   - **지구과학적 의의**: **지구의 자전축 기울기**와 **공전 궤도**의 상호작용\n",
      "\n",
      "---\n",
      "\n",
      "### 🔍 요약\n",
      "태풍은 **계절성이 있지만**, **가을에만 특별히 일어나는 현상은 아닙니다**.  \n",
      "대신 **단풍**, **이시계**, **극야/극주 변화**가 **가을에 특히 뚜렷한 지구과학 현상**입니다.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# 프롬프트 템플릿 정의 (부분 변수 적용)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{season}에 일어나는 대표적인 지구과학 현상은 {phenomenon}이 맞나요? \\\n",
    "        {season}에 주로 발생하는 지구과학 현상을 3개 알려주세요\",\n",
    "    input_variables=[\"phenomenon\"],  # 사용자 입력 필요\n",
    "    partial_variables={\"season\": get_current_season()}  # 동적으로 계절 값 할당\n",
    ")\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "# 특정 계절의 현상 질의\n",
    "query = prompt.format(phenomenon=\"태풍 발생\")\n",
    "result = llm.invoke(query)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\" 프롬프트: {query}\")\n",
    "print(f\" 모델 응답: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20b2ac0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 계절: 가을\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "        \n",
    "season_name = get_current_season()\n",
    "print(f\"현재 계절: {season_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "412f5602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 가을에 발생하는 자연 현상:\n",
      "가철(9~11월)에 뚜렷이 나타나는 대표적인 지구과학 현상 3가지는 다음과 같습니다.\n",
      "\n",
      "1. 아시아 계절풍(겨울모슨) 전환  \n",
      "   태양 고도가 낮아지면서 아시아 대륙이 급속히 식고, 북서풍이 생겨나면서 고기압이 발달합니다. 이로 인해 동아시아 지역에 맑고 건조한 날씨가 이어지고, 온난·다습한 여름 모슨에서 건조·강한 겨울 모슨으로 바뀝니다.\n",
      "\n",
      "2. 열역학적 계절 지연(단풍·낙엽)  \n",
      "   일사량·기온이 급감하더라도 토양과 수면은 여름에 저장한 열을 서서히 방출하기 때문에 실제로 기온이 떨어지는 속도보다 식생 반응이 느립니다. 이 “열 관성” 덕에 단풍·낙엽이 나타나는 시기가 입동보다 2~4주 늦춰지며, 낙엽층 분해로 토양 유기탄소가 증가하는 계절순환을 완성합니다.\n",
      "\n",
      "3. 태풍의 고위도 회피·동아상 변성  \n",
      "   가을이 되면 제트기류가 남하하면서 태풍이 한반도 근해로 북상하기보다 동쪽으로 크게 꺾어 일본 열도나 북태평양으로 빠지는 경우가 많아집니다. 이 과정에서 해수면 온도가 떨어지면서 태풍은 열대저기압 특성을 잃고 “온대저기압”으로 변성되어 강풍·호우를 동반한 저기압 폭풍이 됩니다.\n"
     ]
    }
   ],
   "source": [
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{season}에 주로 발생하는 대표적인 지구과학 현상 3가지를 알려주세요. \"\n",
    "    \"각 현상에 대해 간단한 설명을 포함해주세요.\"\n",
    ")\n",
    "\n",
    "chain2 = (\n",
    "    {\"season\": lambda x : season_name}\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "\n",
    ")\n",
    "\n",
    "# 실행: 현재 계절에 따른 자연 현상 추천\n",
    "response = chain2.invoke({})\n",
    "print(f\"\\n {season_name}에 발생하는 자연 현상:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f7a89d",
   "metadata": {},
   "source": [
    "* API 호출 데이터, 시간 정보, 사용자 정보 등을 반영할 때 매우 유용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b72d4225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 현재 1달러 = 1409.34원 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\n",
      " 모델 응답: 현재 환율: **1 USD = 1,409.34 KRW**  \n",
      "(2025년 6월 24일 기준, 서울외환시장 종가)\n",
      "\n",
      "---\n",
      "\n",
      "### 📊 **환율 분석 요약**\n",
      "| 항목 | 설명 |\n",
      "|------|------|\n",
      "| **레벨** | **1,400원대 중반** – 2022년 3월 이후 **최고치** 근접 |\n",
      "| **최근 추세** | **약 2개월 연속 상승** (5월 초 1,360원 → 현재 1,409원, +3.6%) |\n",
      "| **상승 요인** | ① 미국 금리 고점 지속 (연준 5.25~5.50%) ② 한미 금리차 역전 ③ 원유·철강 등 수입물가 상승 ④ 중국 경기 둔화에 따른 수출 둔화 우려 |\n",
      "| **하락 리스크** | ① 한은의 내년 상반기 금리 인하 시사 ② 미국의 조기 금리 인하 시그널 ③ 달러 약세 재개 |\n",
      "\n",
      "---\n",
      "\n",
      "### 🔍 **핵심 분석 포인트**\n",
      "\n",
      "#### 1. **금리차 역전이 환율의 가장 강력한 추진력**\n",
      "- **미국 실효금리** = 5.25~5.50%  \n",
      "- **한국 실효금리** = 3.50%  \n",
      "→ **역전폭 1.75~2.00%p**로, **캐리트레이드**(원화 매도·달러 매수) 유입 지속\n",
      "\n",
      "#### 2. **수입물가 상승 → 달러 수요 증가**\n",
      "- **두바이유** 배럴당 $82 → $90대 초반 상승  \n",
      "- **철광석·철강** 가격도 10~15% 상승  \n",
      "→ **에너지·원자재 수입 증가**로 **달러 수요↑ → 원화 약세 압력↑**\n",
      "\n",
      "#### 3. **수출 둔화 vs 수입 증가 → 경상수지 적자 우려**\n",
      "- **5월 수출** 전년비 +1.2% (기대치 하회)  \n",
      "- **5월 수입** 전년비 +3.4%  \n",
      "→ **5월 경상수지** 4억 달러 **적자** (2개월 연속)  \n",
      "→ **경상수지 악화**는 **원화 약세의 구조적 요인**으로 작용\n",
      "\n",
      "---\n",
      "\n",
      "### 🎯 **향후 전망 (3개월 내)**\n",
      "\n",
      "| 시나리오 | 환율 범위 | 확률 | 근거 |\n",
      "|----------|-----------|------|------|\n",
      "| **강달러 지속** | 1,420~1,460원 | 45% | 연준 고금리 장기화 + 한은 인하 시사 |\n",
      "| **달러 약세 전환** | 1,370~1,400원 | 35% | 미국 물가 둔화 → 연준 9월 인하 재시사 |\n",
      "| **급등 리스크** | 1,480원↑ | 20% | 중동 지정학 리스크 확대 or 유가 $100↑ |\n",
      "\n",
      "---\n",
      "\n",
      "### 🧭 **투자자/기업 대응 전략**\n",
      "\n",
      "#### ✅ **수입 기업**\n",
      "- **3개월 내 달러 결제 물량**은 **1,420원 이하에서 선물환 헤지** 권장  \n",
      "- **6개월 이상 장기물**은 **분할 헤지**로 상승 리스크 대비\n",
      "\n",
      "#### ✅ **수출 기업**\n",
      "- **현물환 매도 시점**은 **1,400원 이상에서 실시**  \n",
      "- **중소 수출기업**은 **수출보험공사(K-sure)의 환율보험** 활용 권장\n",
      "\n",
      "#### ✅ **개인 투자자**\n",
      "- **원화 약세 수혜주** : **항공·해운·정유·석유화학**  \n",
      "- **원화 강세 수혜주** : **항공사(유류비↓), 수입식품·화장품**  \n",
      "- **캐리트레이드**는 **금리차 축소 시** 급속 **청산** 가능 → **레버리지 원화 표면 금융상품**은 **고위험**\n",
      "\n",
      "---\n",
      "\n",
      "### 📌 **핵심 체크포인트**\n",
      "- **7월 FOMC** → **점도표 개정**이 **9월 인하 시사**의 **가장 중요한 트리거**  \n",
      "- **한은 금통위(7월 11일)** → **동결 확정** 시 **원화 약세 지속**  \n",
      "- **중국 2분기 GDP(7월 15일)** → **기대치 하회 시** **위안화 약세 → 원화 동반 약화** 가능성\n",
      "\n",
      "---\n",
      "\n",
      "**요약 한 줄:**  \n",
      "“**1,400원 중반은 아직 정점이 아니며, 7월 FOMC 이후에도 1,420~1,460원 테스트 가능성이 높습니다. 수입 기업은 헤지 확대, 수출 기업은 환율 상승 시 매도 기회로 활용하세요.**”\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 실시간 환율을 가져오는 함수\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1달러 = {data['rates']['KRW']}원\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"현재 {info} 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\",\n",
    "    input_variables=[],  # 사용자 입력 없음\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # API에서 가져온 데이터 자동 반영\n",
    ")\n",
    "\n",
    "# 모델에 프롬프트 전달 및 응답 받기\n",
    "response = llm.invoke(prompt.format())\n",
    "\n",
    "# 결과 출력\n",
    "print(\" 프롬프트:\", prompt.format())\n",
    "print(\" 모델 응답:\", response.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-JHcERFOP-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
