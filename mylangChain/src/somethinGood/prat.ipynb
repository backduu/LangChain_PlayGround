{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ed954ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq 다뤄보기\n"
     ]
    }
   ],
   "source": [
    "print(\"Groq 다뤄보기\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2429280b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_y\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bc9b534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['prompt'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['prompt'], input_types={}, partial_variables={}, template='{prompt}'), additional_kwargs={})]\n",
      "System: 당신은 개발자입니다.\n",
      "Human: AI 개발자란 무엇일까요?\n"
     ]
    }
   ],
   "source": [
    "# Prompt + LLM + output\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 개발자입니다.\"),\n",
    "    (\"user\", \"{prompt}\")\n",
    "])\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(prompt=\"AI 개발자란 무엇일까요?\")\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b880c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답:  AI 개발자란 **인공지능(AI) 기술을 설계·구현·운영하는 전문가**를 말합니다. 일반적인 소프트웨어 개발자가 애플리케이션 로직, 데이터베이스, 프론트엔드·백엔드 등을 다루는 데 비해, AI 개발자는 다음과 같은 핵심 작업을 수행합니다.\n",
      "\n",
      "| 분야 | 주요 업무 | 사용 기술·툴 |\n",
      "|------|-----------|--------------|\n",
      "| **데이터 엔지니어링** | 학습에 사용할 데이터를 수집·정제·전처리 | Python (pandas, NumPy), SQL, Apache Spark, Airflow |\n",
      "| **모델 설계·학습** | 문제에 맞는 알고리즘 선택·모델 구조 설계·학습 파라미터 튜닝 | TensorFlow, PyTorch, Keras, scikit‑learn, JAX |\n",
      "| **모델 평가·검증** | 정확도, 정밀도·재현율, ROC‑AUC 등 지표 계산·교차 검증·오버피팅 방지 | MLflow, Weights & Biases, TensorBoard |\n",
      "| **배포·서빙** | 모델을 API·앱·엣지 디바이스에 배포·실시간 추론·스케일링 | Docker, Kubernetes, FastAPI, TensorRT, ONNX, AWS SageMaker, Azure ML |\n",
      "| **모니터링·운영** | 추론 성능, 데이터 드리프트, 오류 로그 감시·주기적 재학습 | Prometheus, Grafana, ELK stack, Evidently AI |\n",
      "| **윤리·법규** | 편향·공정성·프라이버시 검토·규제 준수 | IBM AI Fairness 360, Google What‑If Tool, GDPR/CCPA 가이드라인 |\n",
      "\n",
      "### AI 개발자가 갖춰야 할 핵심 역량\n",
      "\n",
      "1. **프로그래밍 실력**  \n",
      "   - Python이 기본이며, C++/Java 등 성능 최적화가 필요한 경우도 있음.  \n",
      "2. **수학·통계 지식**  \n",
      "   - 선형대수, 확률·통계, 최적화 이론을 이해해야 모델을 설계하고 튜닝할 수 있다.  \n",
      "3. **머신러닝/딥러닝 이론**  \n",
      "   - 지도학습, 비지도학습, 강화학습, 트랜스포머, CNN, RNN 등 주요 알고리즘에 대한 이해.  \n",
      "4. **데이터 처리 능력**  \n",
      "   - 대규모 데이터 파이프라인 구축·ETL, 결측치·노이즈 처리 경험.  \n",
      "5. **클라우드·DevOps 지식**  \n",
      "   - AWS, GCP, Azure 등 클라우드 서비스와 CI/CD, 컨테이너화, 오케스트레이션 경험.  \n",
      "6. **문제 해결·비즈니스 이해**  \n",
      "   - 실제 비즈니스 문제를 AI 솔루션으로 전환하고, ROI를 평가할 수 있어야 함.  \n",
      "7. **윤리·책임감**  \n",
      "   - AI 모델이 초래할 수 있는 사회적·법적 영향을 고려하고, 투명성을 확보한다.  \n",
      "\n",
      "### AI 개발자 유형 (예시)\n",
      "\n",
      "| 유형 | 초점 | 대표 업무 |\n",
      "|------|------|-----------|\n",
      "| **연구형** | 새로운 알고리즘·논문 구현 | 최신 논문 재현·성능 개선·학술 발표 |\n",
      "| **프로덕션형** | 모델을 서비스에 안정적으로 적용 | 파이프라인 자동화·실시간 추론·A/B 테스트 |\n",
      "| **데이터형** | 데이터 품질·특성 엔지니어링 | 데이터 라벨링·피처 스토어 구축·데이터 거버넌스 |\n",
      "| **MLOps 엔지니어** | AI 시스템 운영·CI/CD | 모델 레지스트리·자동 재학습·모니터링 대시보드 |\n",
      "\n",
      "### 시작하는 방법\n",
      "\n",
      "1. **기초 학습**  \n",
      "   - Python, NumPy, pandas, scikit‑learn → 기본 머신러닝 구현  \n",
      "2. **딥러닝 프레임워크**  \n",
      "   - TensorFlow/Keras 또는 PyTorch 튜토리얼 진행  \n",
      "3. **프로젝트 경험**  \n",
      "   - Kaggle 대회, 오픈소스 프로젝트, 개인 포트폴리오(예: 이미지 분류, 텍스트 요약)  \n",
      "4. **클라우드·MLOps**  \n",
      "   - AWS SageMaker, GCP AI Platform, Azure ML 중 하나 선택해 모델 배포 실습  \n",
      "5. **윤리·법규 학습**  \n",
      "   - AI 윤리 가이드라인, GDPR·CCPA 등 데이터 보호 규정 이해  \n",
      "\n",
      "---\n",
      "\n",
      "**요약**  \n",
      "AI 개발자는 데이터부터 모델, 배포·운영, 그리고 윤리·법규까지 AI 시스템 전 과정을 설계·구현·관리하는 전문가입니다. 프로그래밍·수학·머신러닝 이론을 바탕으로 데이터 파이프라인을 구축하고, 최신 모델을 학습·검증한 뒤, 클라우드·컨테이너 환경에 안정적으로 서비스합니다. 지속적인 학습과 실전 프로젝트 경험이 성공적인 AI 개발자의 핵심입니다.\n"
     ]
    }
   ],
   "source": [
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    # invoke는 LangChain의 Runnable 인터페이스 메소드\n",
    "    # invoke의 반환값은 보통 AIMessage 타입\n",
    "    print(\"응답: \", response.content)\n",
    "    # response.text는 shortcut 속성으로 제공되기도 하지만, 공식적으론 response.text를 쓰는 게 낫다.\n",
    "except Exception as e:\n",
    "    print(f\"오류:: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1572707f",
   "metadata": {},
   "source": [
    "### 🔑 LCEL\n",
    "- LangChain Expression Language 의 약자\n",
    "- LangChain의 다양한 컴포넌트(프롬프트, 모델, 파서, 리트리버 등)를 표준화된 방식(Runnable 인터페이스) 으로 연결하는 문법\n",
    "- 파이프(|) 연산자를 사용해 마치 유닉스 파이프라인처럼 여러 단계를 직관적으로 연결 가능\n",
    "\n",
    "\n",
    "### ✨ LCEL의 특징\n",
    "- 선언적 구성: \"무엇을 하고 싶은지\"만 정의 → 내부 실행 방식은 LangChain이 처리\n",
    "- 동기/비동기/스트리밍 지원: 같은 체인을 invoke, ainvoke, stream, astream 등으로 호출 가능\n",
    "- 병렬 실행 최적화: 독립적인 단계는 자동으로 병렬 처리\n",
    "- 재시도/대체 경로: 특정 단계 실패 시 fallback 설정 가능\n",
    "- 중간 결과 접근: 체인 실행 중간 단계 결과도 확인 가능\n",
    "- 스키마 기반 입출력 검증: Pydantic/JSONSchema로 입력·출력 유효성 검사\n",
    "- LangSmith 통합: 실행 로그와 디버깅 지원\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f09cfcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**LangChain(랭체인)**은 **대형 언어 모델(LLM)**을 활용한 **응용 프로그램**을 **쉽게 설계·구현**할 수 있게 도와주는 **오픈소스 프레임워크**입니다.  \n",
      "\n",
      "---\n",
      "\n",
      "## 1. 왜 필요할까?\n",
      "- LLM 자체는 “텍스트를 생성하는 엔진”에 불과합니다.  \n",
      "- 실제 서비스에서는 **프롬프트 관리**, **다중 모델 연계**, **외부 데이터·도구와의 연동**, **대화 기억(메모리)**, **에러 핸들링** 등 여러 부가 로직이 필요합니다.  \n",
      "- LangChain은 이런 부가 기능들을 **재사용 가능한 컴포넌트** 형태로 제공해, 개발자가 **핵심 비즈니스 로직**에 집중하도록 돕습니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. 핵심 개념\n",
      "\n",
      "| 개념 | 설명 | 예시 |\n",
      "|------|------|------|\n",
      "| **PromptTemplate** | 프롬프트를 변수화·재사용 가능한 템플릿으로 정의 | `\"다음 문장을 요약해 주세요: {text}\"` |\n",
      "| **Chain** | 여러 LLM 호출·프롬프트·도구를 **순차** 혹은 **분기** 형태로 연결 | `Prompt → LLM → Post‑Processing` |\n",
      "| **Agent** | **도구(tool)** 를 동적으로 선택·호출하며 목표를 달성하는 **자율적인** 체계 | “날씨를 알려줘” → 검색 도구 호출 → LLM 요약 |\n",
      "| **Memory** | 대화·작업의 **컨텍스트**를 저장·관리해 다음 호출에 활용 | 대화 히스토리, 작업 진행 상황 |\n",
      "| **Retriever** | 벡터 DB·검색 엔진 등에서 **관련 문서**를 찾아 LLM에 제공 | RAG(Retrieval‑Augmented Generation) |\n",
      "| **Tool** | 외부 API·함수·스크립트 등 LLM이 직접 호출할 수 있는 **작업 단위** | 계산기, 웹 검색, 데이터베이스 쿼리 등 |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. 주요 구성 요소와 흐름\n",
      "\n",
      "1. **PromptTemplate** → 2. **LLM (OpenAI, Anthropic, Llama 등)** → 3. **Chain**(필요 시 여러 단계 연결) → 4. **Memory/Retriever**(컨텍스트 보강) → 5. **Agent**(도구 선택) → 6. **Output**  \n",
      "\n",
      "이 흐름을 파이썬 코드로 간단히 표현하면:\n",
      "\n",
      "```python\n",
      "from langchain import PromptTemplate, LLMChain, OpenAI\n",
      "\n",
      "# 1️⃣ 프롬프트 템플릿 정의\n",
      "template = PromptTemplate(\n",
      "    input_variables=[\"question\"],\n",
      "    template=\"다음 질문에 대해 친절히 답변해 주세요:\\n{question}\"\n",
      ")\n",
      "\n",
      "# 2️⃣ LLM 인스턴스 (예: OpenAI GPT‑3.5)\n",
      "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
      "\n",
      "# 3️⃣ Chain 생성\n",
      "chain = LLMChain(prompt=template, llm=llm)\n",
      "\n",
      "# 4️⃣ 실행\n",
      "answer = chain.run({\"question\": \"파이썬에서 리스트를 정렬하는 방법은?\"})\n",
      "print(answer)\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 4. 대표적인 사용 사례\n",
      "\n",
      "| 분야 | 구체적 예시 |\n",
      "|------|------------|\n",
      "| **챗봇** | 고객 문의 자동 응답, FAQ 생성, 멀티턴 대화 메모리 |\n",
      "| **검색·요약** | RAG 기반 문서 검색 후 요약, 논문 요약 서비스 |\n",
      "| **데이터 분석** | 자연어로 질문 → SQL 자동 생성 → DB 조회 → 결과 반환 |\n",
      "| **자동화** | “이번 주 매출 보고서 만들어줘” → 파일 읽기·분석·보고서 작성 |\n",
      "| **코드 생성·디버깅** | 자연어 명세 → 코드 스니펫 생성 → 테스트·수정 루프 |\n",
      "| **멀티모달** | 텍스트+이미지 입력을 받아 설명·분류·캡션 생성 (LangChain + Vision 모델) |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. 장점 & 단점\n",
      "\n",
      "### 장점\n",
      "- **모듈화**: Prompt, LLM, Tool 등을 독립적으로 교체·조합 가능  \n",
      "- **생산성**: 복잡한 RAG, Agent 로직을 몇 줄 코드로 구현  \n",
      "- **다양한 연동**: OpenAI, Azure, Cohere, HuggingFace, LangChain Hub 등 풍부한 모델·데이터소스 지원  \n",
      "- **커뮤니티**: 활발한 오픈소스 생태계와 예제, 템플릿이 풍부  \n",
      "\n",
      "### 단점\n",
      "- **추상화 비용**: 초보자에게는 “Chain”, “Agent”, “Memory” 개념이 다소 헷갈릴 수 있음  \n",
      "- **성능 최적화**: 기본 구현이 편리하지만, 고성능 서비스에서는 직접 튜닝이 필요할 수 있음  \n",
      "- **버전 관리**: 빠르게 업데이트되는 패키지라 API 변화에 주의 필요  \n",
      "\n",
      "---\n",
      "\n",
      "## 6. 시작하기 (간단 가이드)\n",
      "\n",
      "1. **Python 환경 준비**  \n",
      "   ```bash\n",
      "   pip install langchain openai  # 기본 패키지\n",
      "   ```\n",
      "\n",
      "2. **OpenAI API 키 설정**  \n",
      "   ```bash\n",
      "   export OPENAI_API_KEY=\"sk-...\"\n",
      "   ```\n",
      "\n",
      "3. **첫 번째 체인 만들기** (위 예시 참고)\n",
      "\n",
      "4. **LangChain Hub**에서 미리 만든 **Chain**·**Prompt**·**Agent** 템플릿을 바로 사용 가능  \n",
      "   ```python\n",
      "   from langchain import hub\n",
      "   chain = hub.load(\"hwchase17/openai-chat\")\n",
      "   ```\n",
      "\n",
      "5. **배포** – FastAPI, Flask, LangServe 등과 결합해 API 형태로 서비스 가능  \n",
      "\n",
      "---\n",
      "\n",
      "## 7. 참고 자료\n",
      "\n",
      "- **공식 문서**: https://python.langchain.com/  \n",
      "- **GitHub**: https://github.com/langchain-ai/langchain  \n",
      "- **LangChain Hub**: 다양한 프리빌트 체인·프롬프트 공유  \n",
      "- **튜토리얼**: “LangChain Quickstart” (YouTube, Medium)  \n",
      "\n",
      "---\n",
      "\n",
      "### 한 줄 요약\n",
      "> **LangChain은 LLM을 활용한 복합 애플리케이션을 **프롬프트, 체인, 에이전트, 메모리** 등 재사용 가능한 블록으로 구성해 빠르게 만들 수 있게 해 주는 파이썬 기반 프레임워크입니다.**  \n",
      "\n",
      "궁금한 점이나 실제 코드 구현을 도와드릴 부분이 있으면 언제든 물어보세요! 🚀\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# StrOutputParser가 AIMessage를 받아서 순수 문자열로 변환해줌.\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "response = chain.invoke({\"prompt\":\"langchain은 뭐야??\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3857e53",
   "metadata": {},
   "source": [
    "# 📝 StrOutputParser 정리\n",
    "## 1. 개념\n",
    "- LangChain Core에서 제공하는 OutputParser 중 하나\n",
    "- LLM의 응답(AIMessage)을 순수 문자열(str) 로 변환해주는 역할\n",
    "- 즉, 모델이 반환하는 메시지 객체에서 .content 부분만 뽑아내서 문자열로 돌려줌\n",
    "\n",
    "## 2. 동작 방식\n",
    "- LLM → AIMessage 객체 생성\n",
    "(예: AIMessage(content=\"아메리카노는 4,500원입니다.\"))\n",
    "- StrOutputParser → AIMessage.content 만 추출\n",
    "- 최종 반환값: \"아메리카노는 4,500원입니다.\" (str 타입)\n",
    "\n",
    "## 3. 사용 예시\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "### 프롬프트\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"너는 친절한 카페 직원이야.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "### 모델\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "### 파서\n",
    "parser = StrOutputParser()\n",
    "\n",
    "### LCEL 체인 구성\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "### 실행\n",
    "response = chain.invoke({\"question\": \"아메리카노 가격 알려줘\"})\n",
    "print(type(response))   # <class 'str'>\n",
    "print(response)         # \"아메리카노는 4,500원입니다.\"\n",
    "\n",
    "\n",
    "\n",
    "## 4. 주의할 점\n",
    "- StrOutputParser를 쓰면 반환값이 문자열이므로 response.content 를 쓰면 에러 발생\n",
    "- 그냥 response 자체가 최종 텍스트임\n",
    "- 만약 AIMessage 객체 그대로 쓰고 싶다면 StrOutputParser 를 체인에 붙이지 않으면 됨\n",
    "\n",
    "## 5. 활용 포인트\n",
    "- 단순히 텍스트 응답만 필요할 때 가장 간단하게 사용 가능\n",
    "- JSON, 구조화된 데이터가 필요하다면 JsonOutputParser, PydanticOutputParser 같은 다른 파서를 사용\n",
    "\n",
    "# 👉 요약:\n",
    "StrOutputParser = LLM 응답(AIMessage) → 문자열(content)만 추출해주는 변환기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee10d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-JHcERFOP-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
